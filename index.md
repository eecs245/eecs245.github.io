---
layout: page
title: ðŸ¡ Home
description: >-
  "Information about EECS 245: Mathematics for Machine Learning in Fall 2025 at the University of Michigan."
nav_order: 1
---

# Mathematics for Machine Learning ðŸ§ 
{: .no_toc }
{: .mb-2 }
EECS 245*, Fall 2025 at the <b><span style="background-color: #FFCB05; color: #00274C">University of Michigan</span></b>
{: .no_toc }
{: .fs-6 .fw-300 .mb-2 }

<small>4 credits â€¢ Open to all majors â€¢ Satisfies linear algebra requirement for CS majors and EECS 445</small><br>
<small>*Officially numbered EECS 298-004 and EECS 298-005; EECS 245 will be used starting Winter 2026</small>

{% for staffer in site.staffersnobio %}
{{ staffer }}
{% endfor %}

{: .green }
**Welcome to Mathematics for Machine Learning!** The course website is currently under construction. In the meantime, refer to the description below and the [FAQs](faqs) for more information.

<!-- {: .green }
Linear algebra forms the basis of modern machine learning and artificial intelligence. _Mathematics for Machine Learning_ will introduce students to the theory of linear algebra while exposing them to its applications to real-world machine learning problems using Python. After taking this course, students will understand the mathematical underpinnings of linear regression, neural networks, gradient descent, decision trees, dimensionality reduction, and other core ideas in machine learning. -->

<!-- 1. TOC
{:toc} -->

## Content

Linear algebra, calculus, and probability form the basis of modern machine learning and artificial intelligence. **This course will introduce linear algebra from scratch by focusing on methods and examples from machine learning.** It will give students strong intuition for how linear algebra, calculus and probability are used in machine learning. While the course is primarily theoretical, we'll look at practical applications involving real data in Python each week, so that students are able to apply what they've learned.

Each topic below corresponds to ~1-2 lectures.

- Python, Jupyter Notebooks, and `numpy`.
- Introduction to supervised learning: parameters, loss functions, and empirical risk minimization.
- Optimization in single and multiple variables.
- Vectors, the dot product, and projections.
- Vector spaces and spans.
- Matrices, linear independence, and rank.
- Multiple linear regression, using both projections and vector calculus.
- Partial derivatives and gradient vectors.
- Gradient descent.
- Eigenvalues and eigenvectors.
- Singular value decomposition (SVD) and Principal Components Analysis (PCA).
- The PageRank algorithm.
- Random variables.
- Independence and conditional independence.
- Maximum likelihood estimation.


## Format

- **Lectures (TuTh 3-4:30PM, 1013 DOW)**: Introduce core content in an interactive format. Recorded, and attendance will **not** be taken.
- **Labs (W 12:30-2:30PM or W 4:30-6:30PM)**: Provide supervised practice with mathematical ideas and a venue for exploring practical applications in Python. Attendance **will** be taken.
- **Homeworks**: Assigned and due weekly. Will consist of ~80% math on paper and ~20% code in Python.
- **Exams**: 1-2 Midterm Exams and one Final Exam, all in-person and on-paper.


